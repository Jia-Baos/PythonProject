import torch
import torch.nn as nn
import numpy as np

y_softmax = np.array(
    [
        [
            [
                0.0319533345695271,
                0.0262210133693412,
                0.0405548727460100,
                0.0293328834922530,
                0.0235946021815836,
                0.0480142162870594,
                0.0287704618407728,
                0.0351268637054168,
                0.0448965052477630,
                0.0323234212279283,
                0.0471297269219778,
                0.0334908192070999,
                0.0447002788315031,
                0.0456320948241136,
                0.0351234600906292,
                0.0230148922614546,
                0.0314192811142228,
                0.0344970346892286,
                0.0295721871384341,
                0.0274843752526059,
                0.0513304969210734,
                0.0346911732659917,
                0.0548353372646645,
                0.0333729892573427,
                0.0486999624899632,
                0.0335606882517763,
                0.0506570275502634,
            ]
        ],
        [
            [
                0.0442961938109001,
                0.0303627704208565,
                0.0258378526020265,
                0.0458891577161975,
                0.0537920435977104,
                0.0288868677848477,
                0.0407349328912650,
                0.0322806067098565,
                0.0479099042067772,
                0.0449106925711146,
                0.0246080887866719,
                0.0492939884049119,
                0.0560191619281624,
                0.0348218517081914,
                0.0504056201105211,
                0.0374815087428365,
                0.0243023731122621,
                0.0254237678526359,
                0.0312736688595233,
                0.0440148630768450,
                0.0475321094768427,
                0.0458687788283468,
                0.0286268732637606,
                0.0355125367928648,
                0.0227774801386588,
                0.0232784351056503,
                0.0238578714997625,
            ]
        ],
        [
            [
                0.0382974368377362,
                0.0318777312135849,
                0.0234868589674224,
                0.0318722744011979,
                0.0225185381516373,
                0.0205262552943881,
                0.0454877627911883,
                0.0340316234294017,
                0.0492219436202117,
                0.0389936131137926,
                0.0347966678592871,
                0.0439093761642613,
                0.0467935124498177,
                0.0522292290638150,
                0.0194384495697102,
                0.0461625681675025,
                0.0358483354617907,
                0.0522835019782284,
                0.0329308772273817,
                0.0313826141807340,
                0.0432967801742709,
                0.0243997674509821,
                0.0319708630090250,
                0.0478266566415420,
                0.0345149265806327,
                0.0452367066323343,
                0.0406651295681235,
            ]
        ],
        [
            [
                0.0383195501689954,
                0.0272951137973125,
                0.0415288927451887,
                0.0231838517718695,
                0.0398823138441169,
                0.0413022813256117,
                0.0442442329310963,
                0.0519730489462436,
                0.0569558497142297,
                0.0460166028890008,
                0.0381459528257684,
                0.0539623316283564,
                0.0380942573161036,
                0.0216922730554261,
                0.0240667868142706,
                0.0505358960731075,
                0.0346143968556499,
                0.0496415831760055,
                0.0262949856792733,
                0.0370498580320465,
                0.0400391034751884,
                0.0220202876462848,
                0.0394362954874324,
                0.0306423990773223,
                0.0224099657044701,
                0.0347974172676594,
                0.0258544717519696,
            ]
        ],
        [
            [
                0.0274643882294982,
                0.0298236175649923,
                0.0281155092606543,
                0.0293378537462717,
                0.0253418924737544,
                0.0458330002578632,
                0.0321905618820226,
                0.0416126048467898,
                0.0486654573566434,
                0.0400017201897758,
                0.0414964341812715,
                0.0379014590893513,
                0.0274877024782956,
                0.0396528862221281,
                0.0569859416555112,
                0.0581911831104043,
                0.0318201830875284,
                0.0299122412570334,
                0.0427250763149338,
                0.0460679863549903,
                0.0368492548068844,
                0.0298379764585031,
                0.0626610201269008,
                0.0263607892806820,
                0.0269913345266294,
                0.0279900073565483,
                0.0286819178841385,
            ]
        ],
    ]
).astype("float32")


labels = np.array([[3, 1, 20]]).astype("int32")
input_lengths = np.array([5]).astype("int64")
label_lengths = np.array([3]).astype("int64")

ctc_input = torch.tensor(y_softmax).log()
labels = torch.tensor(labels)
input_lengths = torch.tensor(input_lengths)
label_lengths = torch.tensor(label_lengths)

ctc_loss = nn.CTCLoss()
loss = ctc_loss(ctc_input, labels, input_lengths, label_lengths)
print("loss is {}".format(loss))

print(
    "image shape: {}".format(ctc_input.shape)
)  # batch_sizie*height*wdith -> batch_size*channels*height*wdith
print("target shape: {}".format(labels.shape))  # batch_size -> batch_size*cls
print("input_len: {}".format(input_lengths))
print("target_len: {}".format(input_lengths))
